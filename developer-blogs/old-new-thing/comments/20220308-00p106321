Chris Blume  March 9, 2022


  1  Collapse this comment
Copy link
I believe there is a typo.
‚Äú(100¬≤a + 100b + 100c)d = 100¬≤ad + 100bd + cd‚Äù
That should have been just ‚Äúc‚Äù, not ‚Äú100c‚Äù on the left side.





Scarlet Manuka  March 8, 2022


  0  Collapse this comment
Copy link
In the ‚Äúquick mental check‚Äù part, do you mean 2¬π‚Å∞ rather than 10¬π¬π?





Michael Dunn  March 8, 2022


  0  Collapse this comment
Copy link
I‚Äôm gonna need a Microspeak post about ‚Äústrength-reduce‚Äù üôÇ





Raymond Chen Author
March 8, 2022


  0  Collapse this comment
Copy link
Strength reduction




Letao Wang  March 8, 2022
¬∑ Edited

  0  Collapse this comment
Copy link
The techniques you describe are cool, but from a narrative perspective, I feel that introducing new rules in part 2 is not fair.  It completely changes the problem space and possibilities for optimization.
Imagine if in part 3 you change the setup again so darkness can only be 0 or 100%.  Then the program can be ‚Äúoptimized‚Äù to be a no-op when darkness is 0, and a memset(0) when darkness is 100%.





Joshua Hudson  March 8, 2022


  0  Collapse this comment
Copy link
I‚Äôm pretty sure you meant union Pixel not struct Pixel.





Flux  March 8, 2022


  0  Collapse this comment
Copy link
So, the summary of Episode 2 of ‚ÄúOptimizing code to darken a bitmap‚Äù: Making the code run 2.9x times slower. Highlights of Episode 3: How to make the code cause BSOD! üòâ
Joke aside, I hope the 3rd episode justifies this entire post. I‚Äôll keep my fingers crossed. ü§û





Antonio Rodr√≠guez  March 8, 2022
¬∑ Edited

  0  Collapse this comment
Copy link
In the 90s, you would end using a look-up table for the multiplication. Building it takes 256 iterations and 256 bytes of memory, but after that, you replace a multiplication and a division with a byte array access, which is a lot faster. The table even fits inside the meager 8 KB cache of a 486. You could even have several pre-computed tables and use them on demand, saving even more time.
This was used a lot in software renderers for 3D games. It allowed a lot of tricks with the textures: shading, coloring, and even changing individual colors (say, turn...Read moreIn the 90s, you would end using a look-up table for the multiplication. Building it takes 256 iterations and 256 bytes of memory, but after that, you replace a multiplication and a division with a byte array access, which is a lot faster. The table even fits inside the meager 8 KB cache of a 486. You could even have several pre-computed tables and use them on demand, saving even more time.
This was used a lot in software renderers for 3D games. It allowed a lot of tricks with the textures: shading, coloring, and even changing individual colors (say, turn blues to reds while leaving all other colors unchanged). And it was quick enough to apply it per-pixel in the inner texturing loop. In fact, that‚Äôs where the term ‚Äúshader‚Äù comes from: a small piece of code which gets executed once per pixel while applying a texture, to ‚Äúshade‚Äù it.
Ken Silverman, author of the Build engine used in Duke Nukem 3D, Shadow Warrior and Blood, tells an interesting story. During the development of Shadow Warrior, 3D Realms asked him to add MMX support. He played with it, and he found that due to his code being very optimized, and all the palette lookup tricks, it benefited little from SIMD, and in some cases the work of packing/unpacking bytes actually made it run slower (Build, as most game engines of the day, ran in 256-color paletted modes).
Read less







Henry Skoglund  March 8, 2022
¬∑ Edited

  0  Collapse this comment
Copy link
HI, try something like:
void darken(Pixel* first, Pixel* last, int darkness)
{
  int factor = darkness / 8;
  for (; first < last; ++first) {
    uint32_t v = first->v;
    uint32_t onefactor = (v >> 5) & 0x00070707;  // get high 3 bits of r,g,b but leave alpha alone
    for (int f = 0; (f < factor); ++f)
        v -= onefactor;
    first->v = v;
  }

(since we‚Äôre going dark there should be no chance of any overflows or underflows to other bytes)





D√©cio Luiz Gazzoni Filho  March 8, 2022
¬∑ Edited

  0  Collapse this comment
Copy link
That was somewhat predictable. Multiplications are not as expensive as they used to be. I selected a few recent microarchitectures on the uops.info website, and they all show a throughput of 1 multiplication/cycle (not the latency, which is longer, but the multiplier is pipelined). Sure the CPU can process quite a few more instructions/cycle (and it'll have to -- loads, stores, loop increments, branching, etc.), but what good is that if you have to waste all the remaining resources (and then some more) with expensive conversion to a different representation and back?
This might work if the operation is inside of...Read moreThat was somewhat predictable. Multiplications are not as expensive as they used to be. I selected a few recent microarchitectures on the uops.info website, and they all show a throughput of 1 multiplication/cycle (not the latency, which is longer, but the multiplier is pipelined). Sure the CPU can process quite a few more instructions/cycle (and it‚Äôll have to ‚Äî loads, stores, loop increments, branching, etc.), but what good is that if you have to waste all the remaining resources (and then some more) with expensive conversion to a different representation and back?
This might work if the operation is inside of a pipeline with other operations that benefit from this representation, so that you could amortize the conversion cost across many different operations, performing it only at the start and finish.
Of course, and sorry to everyone else for the spoiler, but the highest performing implementation will use SIMD (i.e. AVX2 or AVX-512), and I wouldn‚Äôt bet that this conversion of representation trick would perform better there either. My guess is that the best performing version will simply zero/sign-extend from 8-bit to 16-bit lanes, do a 16-bit/lane multiply, then use shuffling trickery to pick up the most significant byte from each 16-bit lane.
Read less







MGetz  March 8, 2022


  0  Collapse this comment
Copy link
Seems to be just an MSVC issue, clang and gcc will both swap to SIMD if you set the options
No AVX512: https://godbolt.org/z/beGh4qs1K
march=rocketlake https://godbolt.org/z/oPfaj6GsM