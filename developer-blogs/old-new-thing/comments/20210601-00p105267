Aaron Giles  June 1, 2021


  0  Collapse this comment
Copy link
The single-instruction IT limitation may seem weird, but it was an (ultimately doomed) attempt to help processor architects optimize IT usage. The idea was that eventually you would be able to configure the processor to run in a mode where only these forms of IT were permitted.
In this mode, the processor could treat the 16-bit IT instruction plus the subsequent 16-bit instruction as a new single 32-bit conditional instruction. By doing so, you eliminate a lot of the complexity of IT that slows down its implementation, such as maintaining the status bits that track where you were in the...Read moreThe single-instruction IT limitation may seem weird, but it was an (ultimately doomed) attempt to help processor architects optimize IT usage. The idea was that eventually you would be able to configure the processor to run in a mode where only these forms of IT were permitted.
In this mode, the processor could treat the 16-bit IT instruction plus the subsequent 16-bit instruction as a new single 32-bit conditional instruction. By doing so, you eliminate a lot of the complexity of IT that slows down its implementation, such as maintaining the status bits that track where you were in the 4-instruction IT sequence, plus you get rid of other oddities that the microarchitects disliked.
This idea was introduced just as Windows was settling on its ABI, and since it held the promise of making things faster, it was decided to adopt it up front rather than trying to backtrack it later. It wasnâ€™t too limiting (made the compiler simpler, honestly), and there was no significant performance degradation from adding this limitation. (With branch predictors getting bigger and better all the time, conditional execution tends to really only benefit truly unpredictable code anyway.)
Read less