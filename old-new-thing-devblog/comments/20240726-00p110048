Kevin Norris  July 28, 2024


  0  Collapse this comment
Copy link
> (We assume that no code page has a single input byte that converts to multiple Unicode characters.)
I'm not entirely convinced that this is actually true. Some examples:
* In the past, Unicode has encoded some diacritical marks as "precomposed" characters (giving us e.g. U+00E9 LATIN SMALL LETTER E WITH ACUTE), but going forward, I believe the consortium has stated that this is deprecated for new characters in favor of combining accents, so there might be...Read more> (We assume that no code page has a single input byte that converts to multiple Unicode characters.)
I’m not entirely convinced that this is actually true. Some examples:
* In the past, Unicode has encoded some diacritical marks as “precomposed” characters (giving us e.g. U+00E9 LATIN SMALL LETTER E WITH ACUTE), but going forward, I believe the consortium has stated that this is deprecated for new characters in favor of combining accents, so there might be some encoding that has a precomposed character with no direct equivalent in Unicode. But I would assume they’ve already covered all the precomposed characters that were present in major pre-Unicode encodings, so I think this is unlikely to be an issue in practice. Of course, if you’re normalizing your Unicode output as NFD or NFKD, then this goes out the window and all diacritical marks will expand the size of the buffer, but you can do that as a separate step after re-encoding.
* Some dingbats display with an emoji presentation if not suffixed with U+FE0E VARIATION SELECTOR 15. In practice, most dingbats in Unicode were at some point encoded in some other encoding (or font, in the case of Wingdings and its descendants), and then included in Unicode for compatibility reasons. In nearly all cases, the reasonable way to re-encode a dingbat is with text presentation, because that’s how it looked in the original. So it is more or less inevitable that some encoding out there will require the variation selector suffix when re-encoded into Unicode.
* On a related note, if re-encoding CJK, you have to either live with Han unification (which will inevitably annoy someone), or mark up characters with variation selectors as described in the Ideographic Variation Database to indicate which glyph variant you want. This can significantly expand the size of your output buffer.
Read less







Neil Rashbrook  July 28, 2024


  0  Collapse this comment
Copy link
Although I agree that your output buffer needs to be at least as long as your input buffer, I found your logic as to why this is the case to be confusing. In particular, if you're referring to code units as bytes for UTF-8 and words for UTF-16 then UTF-16 never uses more code units than UTF-8 does, even outside the BMP, while it uses more bytes than UTF-8 for U+0000 to U+007F and fewer...Read moreAlthough I agree that your output buffer needs to be at least as long as your input buffer, I found your logic as to why this is the case to be confusing. In particular, if you’re referring to code units as bytes for UTF-8 and words for UTF-16 then UTF-16 never uses more code units than UTF-8 does, even outside the BMP, while it uses more bytes than UTF-8 for U+0000 to U+007F and fewer bytes than UTF-8 for U+0800 to U+FFFF.
Read less