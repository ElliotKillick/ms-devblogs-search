skSdnW  November 5, 2019


  0  Collapse this comment
Copy link
The same question applies to Win 9x? SetFilePointer and friends do not support 64-bit offsets on these systems but is this limit high up in kernel32 or down in the local FAT filesystem driver?





Yuhong Bao  November 5, 2019


  0  Collapse this comment
Copy link
I think no version of DOS or DOS-based Windows supports 64-bit offsets anywhere.




Ivan Kljajic  November 5, 2019


  0  Collapse this comment
Copy link
Wasn't some form of cheap digital tape mass storage available in the mid 80's to the PC? At any rate the need for a 32 bit file pointer is fairly obvious, because 64K isn't enough for everyone, and nobody wants to waste RAM by reducing resolution, reading in whole blocks or whatever.
Well, except one good use case of such a large file would be for a clever algorithm that streamed a stored constant from...Read moreWasn‚Äôt some form of cheap digital tape mass storage available in the mid 80‚Äôs to the PC? At any rate the need for a 32 bit file pointer is fairly obvious, because 64K isn‚Äôt enough for everyone, and nobody wants to waste RAM by reducing resolution, reading in whole blocks or whatever.
Well, except one good use case of such a large file would be for a clever algorithm that streamed a stored constant from a multi gb mainframe tape file (RLYBIGPI.TXT, for example) to efficiently piece-meal calculate a very accurate result (like the perimeter of a circle) for display on a CGA monitor.
Read less







Anders Bagger  November 8, 2019


  0  Collapse this comment
Copy link
I can't remember what actual size, that was avaliable on tape storage. Yet in 1991/92'ish, we had QIC-80 tapes, for the private market, and they stored 128 megabyte non-compressed. And if you compressed the data you backed up, you could essentially store what was around 250 megabyte non-compressed. That said, if the files were zipped or other form of compressed, then you were still only able to store 128 megabyte.
Anyway.
That was in the early...Read moreI can‚Äôt remember what actual size, that was avaliable on tape storage. Yet in 1991/92‚Äôish, we had QIC-80 tapes, for the private market, and they stored 128 megabyte non-compressed. And if you compressed the data you backed up, you could essentially store what was around 250 megabyte non-compressed. That said, if the files were zipped or other form of compressed, then you were still only able to store 128 megabyte.
Anyway.
That was in the early 1990‚Äôs, and though the tools were on Dos for the drive, you were not able to use it as a network drive. Tapes were backup solutions and not drives as such. Two really different type of storage solutions.
Read less







Alex Martin  November 8, 2019


  0  Collapse this comment
Copy link
Extremely nitpicky, and not actually a problem with the concept, but less than 40 digits of pi is enough precision for even ridiculously extreme precision in enormous calculations. NASA JPL uses 15 digits in their interplanetary navigation calculations. But the point still stands; it‚Äôs reasonable that someone would stream a very large amount of data from a single file on a mainframe.




Jake Boeckerman  November 4, 2019


  0  Collapse this comment
Copy link
In the reinventing, it might gain a new acronym: RAVED ‚Äì Redundant Array of Very Expensive Disks?





Joshua Hudson  November 4, 2019


  0  Collapse this comment
Copy link
I suppose you could, if you like daisy chaining VMs. We discovered that DOS didn‚Äôt like talking to Windows Server 2003 when it came out, so anything newer is right out.





cheong00  November 5, 2019


  0  Collapse this comment
Copy link
I think you‚Äôll want to enable IPX/SPX for it to work, although latest DOS network kit should support TCP/IP already.





Neil Rashbrook  November 5, 2019


  0  Collapse this comment
Copy link
Was this a domain controller? It might insist on NTLM2 authentication or SMB signing, which would prevent DOS clients from connecting.




cheong00  November 4, 2019


  0  Collapse this comment
Copy link
On the other hand, ‚Äúwhat would happen if MS-DOS running under virtual machine tried to access a network file bigger than 2GB?‚Äù is a valid question, and you can just tell him to set up a VM or two to check. üòõ





Yuhong Bao  November 4, 2019


  0  Collapse this comment
Copy link
Though SMB is not the same as HTTP. One typically runs on 10Mbit Ethernet, while HTTP did run on T1 lines. This is why it took until IE8 for files larger than 4GB to be added there.





Yuhong Bao  November 4, 2019


  0  Collapse this comment
Copy link
I wonder if the flag in the INT 21/6C00h call that allow access to 4GB files had any effect on DOS redirectors.





GL  November 4, 2019


  0  Collapse this comment
Copy link
I would be surprised if *any* remoting system would remote the low-level operations at all‚Ä¶ BTW, a recent episode of XKCD also talks about cute things that happen when retro-software is emulated on a modern computer.





Will Rosecrans  November 7, 2019


  0  Collapse this comment
Copy link
There are definitely distributed storage systems that work with concurrent block level access.  Something like a StorNext SAN deployment works by connecting a big pile of disks to a bunch of systems over fibrechannel, and each system connected to the disks can do low-level block I/O basically as if it was talking to a private internal drive.  You need a dedicated metadata server (cluster) that the clients all talk to to coordinate where...Read moreThere are definitely distributed storage systems that work with concurrent block level access.  Something like a StorNext SAN deployment works by connecting a big pile of disks to a bunch of systems over fibrechannel, and each system connected to the disks can do low-level block I/O basically as if it was talking to a private internal drive.  You need a dedicated metadata server (cluster) that the clients all talk to to coordinate where exactly files are supposed to live, and who owns which blocks, etc.  It certainly wouldn‚Äôt have been impossible to make that sort of a network storage sharing setup work on PC‚Äôs in the 80‚Äôs.  It just would have been‚Ä¶ odd.
Basically, to try and do a SAN style distributed block filesystem in the 1980‚Äôs on DOS, you probably would have had one of the two machines acting as the metadata server cluster.  (Since, it‚Äôs not like you can spare a whole computer just for that in 1984!)  So the client would ask ‚Äúwhat is the address of hello.txt‚Äù  and then ask ‚Äúwhat is the data at block address 12345.‚Äù  But it would be asking both questions of the same server, which is silly and redundant, so it would have been a performance anti-optimization with the hardware and workloads of the time.
Read less






Alex Martin  November 4, 2019


  0  Collapse this comment
Copy link
Vaguely related to MS-DOS retrocomputing: I designed (but did not implement) a TSR at one point that would implement a user account system and (try to) enforce access control on disk files. It‚Äôs not like it would have actually stopped anyone from, say, bypassing DOS and reading the disk directly, but it was one of those ‚Äúwouldn‚Äôt it be cool if‚Äù projects.